{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import collections\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DIR1 = '/home/iliana/Documents/bagofwords/aftermanualprepro/'\n",
    "vocabulary = []\n",
    "vocabulary_cl = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('t', 'art_gallery2.xlsx')\n",
      "('t', 'bar2.xlsx')\n",
      "('t', 'basketball2.xlsx')\n",
      "('t', 'beach2.xlsx')\n",
      "('t', 'bedroom2.xlsx')\n",
      "('t', 'cafe2.xlsx')\n",
      "('t', 'canals2.xlsx')\n",
      "('t', 'climbing2.xlsx')\n",
      "('t', 'cycling2.xlsx')\n",
      "('t', 'dance2.xlsx')\n",
      "('t', 'fields2.xlsx')\n",
      "('t', 'football2.xlsx')\n",
      "('t', 'forest2.xlsx')\n",
      "('t', 'home2.xlsx')\n",
      "('t', 'horseriding2.xlsx')\n",
      "('t', 'hug2.xlsx')\n",
      "('t', 'kiss2.xlsx')\n",
      "('t', 'kitchen2.xlsx')\n",
      "('t', 'pets2.xlsx')\n",
      "('t', 'playing_music2.xlsx')\n",
      "('t', 'running2.xlsx')\n",
      "('t', 'selfie2.xlsx')\n",
      "('t', 'ski2.xlsx')\n",
      "('t', 'street2.xlsx')\n",
      "('t', 'surfing2.xlsx')\n",
      "('t', 'swimming_pool2.xlsx')\n",
      "('t', 'urban2.xlsx')\n",
      "('t', 'wendys2_clean.xlsx')\n",
      "19166\n",
      "420385\n"
     ]
    }
   ],
   "source": [
    "#make the vocabulary\n",
    "with open(DIR1+'z.txt') as f:\n",
    "    content = f.readlines()\n",
    "\n",
    "for efn in content:\n",
    "\n",
    "    input_filename = efn.strip('\\n')\n",
    "    if input_filename == 'wendys2_clean.xlsx':\n",
    "        column_name = 'imageCaption'\n",
    "    else:\n",
    "        column_name = 'title'\n",
    "    \n",
    "\n",
    "    try:\n",
    "        df_words = pd.read_excel(DIR1+input_filename,index_col=0)[column_name]\n",
    "        print ('t',input_filename)\n",
    "    except:\n",
    "        print ('e',input_filename)\n",
    "\n",
    "\n",
    "  \n",
    "    for i in df_words.index:\n",
    "        df_words.loc[i] = ast.literal_eval(df_words.loc[i])\n",
    "\n",
    "\n",
    "        \n",
    "        for word in df_words.loc[i]:\n",
    "            vocabulary.append(word)\n",
    "\n",
    "vocabulary_cl = sorted(set(vocabulary))\n",
    "\n",
    "print len(vocabulary_cl)\n",
    "print len(vocabulary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print vocabulary_cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counter=collections.Counter(vocabulary)\n",
    "\n",
    "#print(counter)\n",
    "print(counter.most_common(20))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#does not write the file correctly for some reason?!\n",
    "\n",
    "#voc_cl = open('vocabulary_cl.txt', 'w')\n",
    "\n",
    "#for item in vocabulary_cl:\n",
    "    #voc_cl.write(\"%s\\n\" % item)\n",
    "    \n",
    "with open(\"vocabulary_cl.txt\", 'w') as f:\n",
    "    for w in vocabulary_cl:\n",
    "        f.write(str(w) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "voc = {}\n",
    "\n",
    "for i, i_el in enumerate(vocabulary_cl):\n",
    "    voc[i_el] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['great', 'work', 'art', 'artist', 'painting', 'drawing', 'markers', 'paintings', 'ink', 'creative', 'sketch', 'artwork', 'illustration', 'graphic', 'inspiration']\n",
      "<type 'str'>\n",
      "great work art artist painting drawing markers paintings ink creative sketch artwork illustration graphic inspiration\n"
     ]
    }
   ],
   "source": [
    "DIR1 = '/home/iliana/Documents/bagofwords/aftermanualprepro/'\n",
    "df_ag = pd.read_excel(DIR1+'art_gallery2.xlsx')['title']\n",
    "df_ag =df_ag.loc[1]\n",
    "df_ag = ast.literal_eval(df_ag)\n",
    "\n",
    "print df_ag\n",
    "\n",
    "ag = ' '.join(df_ag)\n",
    "print type(ag)\n",
    "print ag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bag_of_words(docs):\n",
    "    \n",
    "    vectorizer = CountVectorizer(analyzer='word',\n",
    "                                vocabulary=voc) #custom vocabulary\n",
    "    bow_repr = vectorizer.fit_transform(docs)\n",
    "    \n",
    "    \n",
    "    return bow_repr.toarray()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 19166)\n",
      "<type 'numpy.ndarray'>\n",
      "[[0 0 0 ..., 0 0 0]]\n",
      "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), array([  831,   842,   849,  4090,  5172,  7407,  7445,  8445,  8661,\n",
      "        8717, 10233, 11873, 11874, 15449, 18972]))\n"
     ]
    }
   ],
   "source": [
    "print bag_of_words([ag]).shape\n",
    "print type(bag_of_words([ag]))\n",
    "print bag_of_words([ag])\n",
    "\n",
    "print np.where(bag_of_words([ag]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((499, 19166), 'art_gallery2.xlsx')\n",
      "((1039, 19166), 'bar2.xlsx')\n",
      "((1055, 19166), 'basketball2.xlsx')\n",
      "((1222, 19166), 'beach2.xlsx')\n",
      "((1240, 19166), 'bedroom2.xlsx')\n",
      "('cafe2.xlsx', 106)\n",
      "((1568, 19166), 'cafe2.xlsx')\n",
      "((882, 19166), 'canals2.xlsx')\n",
      "((1008, 19166), 'climbing2.xlsx')\n",
      "((1786, 19166), 'cycling2.xlsx')\n",
      "((473, 19166), 'dance2.xlsx')\n",
      "((1264, 19166), 'fields2.xlsx')\n",
      "((1549, 19166), 'football2.xlsx')\n",
      "((1789, 19166), 'forest2.xlsx')\n",
      "((1306, 19166), 'home2.xlsx')\n",
      "((1258, 19166), 'horseriding2.xlsx')\n",
      "((1290, 19166), 'hug2.xlsx')\n",
      "((909, 19166), 'kiss2.xlsx')\n",
      "((1620, 19166), 'kitchen2.xlsx')\n",
      "((753, 19166), 'pets2.xlsx')\n",
      "((185, 19166), 'playing_music2.xlsx')\n",
      "((1953, 19166), 'running2.xlsx')\n",
      "((714, 19166), 'selfie2.xlsx')\n",
      "((1267, 19166), 'ski2.xlsx')\n",
      "((1408, 19166), 'street2.xlsx')\n",
      "((472, 19166), 'surfing2.xlsx')\n",
      "((415, 19166), 'swimming_pool2.xlsx')\n",
      "((1542, 19166), 'urban2.xlsx')\n",
      "((8522, 19166), 'wendys2_clean.xlsx')\n"
     ]
    }
   ],
   "source": [
    "DIR1 = '/home/iliana/Documents/bagofwords/aftermanualprepro/'\n",
    "dir2 = 'bow_results/'\n",
    "\n",
    "with open(DIR1+'z.txt') as f:\n",
    "    content = f.readlines()\n",
    "\n",
    "for efn in content:\n",
    "\n",
    "    input_filename = efn.strip('\\n')\n",
    "    output_filename = input_filename.split('.')[0]+'_bow.csv'\n",
    "\n",
    "    if input_filename == 'wendys2_clean.xlsx':\n",
    "        column_name = 'imageCaption'\n",
    "    else:\n",
    "        column_name = 'title'\n",
    "\n",
    "    df_words = pd.read_excel(DIR1+input_filename)[column_name]\n",
    "    bow_array = np.zeros((df_words.shape[0],len(voc.keys())))\n",
    "    \n",
    "    for i in df_words.index:\n",
    "\n",
    "        if not ast.literal_eval(df_words.loc[i]): #in case the list is empty!\n",
    "            print(input_filename,i)\n",
    "\n",
    "        else:\n",
    "            df_words.loc[i] = ' '.join(ast.literal_eval(df_words.loc[i])) \n",
    "            \n",
    "            bow_array[i,:] = bag_of_words([df_words.loc[i]])\n",
    "            \n",
    "    print (bow_array.shape, input_filename)\n",
    "    np.savetxt(dir2+output_filename,bow_array,delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
